{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f7b0b28",
   "metadata": {},
   "source": [
    "# Point Transformer\n",
    "\n",
    "- Utilities\n",
    "1. k-Nearest Neighbor Search\n",
    "2. k-Nearest Neighbor Linear Interpolation\n",
    "3. Farthest Point Sampling\n",
    "- Modules\n",
    "1. Point Transformer Layer\n",
    "2. TransitionDown\n",
    "3. TransitionUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d369c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc71760",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1880e809",
   "metadata": {},
   "source": [
    "### 1. k-Nearest Neighbor Search\n",
    "- Input: points (N, 3) and the number of neighbors K\n",
    "- Output: kNN distances (N, K) and kNN indices (N, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bcc987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_knn(point_cloud, k):\n",
    "    N = len(point_cloud)\n",
    "    \n",
    "    # 1. Compute pairwise distance\n",
    "    delta = point_cloud.view(N, 1, 3) - point_cloud.view(1, N, 3) # (N, N, 3)\n",
    "    dist = torch.sum(delta ** 2, dim=-1) # (N, N)\n",
    "    \n",
    "    # 2. Find k-nearest neighbor indices (Hint: torch.topk)\n",
    "    knn_dist, knn_indices = dist.topk(k=k, dim=-1, largest=False)\n",
    "    \n",
    "    return knn_dist, knn_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61dc0693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 5])\n",
      "torch.Size([100, 5])\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "K = 5\n",
    "\n",
    "points = torch.randn(N, 3)\n",
    "knn_dist, knn_indices = find_knn(points, K)\n",
    "print(knn_dist.shape)\n",
    "print(knn_indices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d7f1db",
   "metadata": {},
   "source": [
    "### 1. k-Nearest Neighbor Search (General Case)\n",
    "- Input: dataset points (N, 3), query points (M, 3), and the number of neighbors K\n",
    "- Output: kNN distances (M, K) and kNN indices (M, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e52f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_knn_general(query_points, dataset_points, k):\n",
    "    M = len(query_points)\n",
    "    N = len(dataset_points)\n",
    "    \n",
    "    # 1. Compute pairwise distance\n",
    "    delta = query_points.view(M, 1, 3) - dataset_points.view(1, N, 3) # (M, N, 3)\n",
    "    dist = torch.sum(delta ** 2, dim=-1) # (M, N)\n",
    "    \n",
    "    # 2. Find k-nearest neighbor indices and corresponding features\n",
    "    knn_dist, knn_indices = dist.topk(k=k, dim=-1, largest=False) # (M, k)\n",
    "    \n",
    "    return knn_dist, knn_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8543777d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 3])\n",
      "torch.Size([25, 3])\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "M = 25\n",
    "K = 3\n",
    "\n",
    "query_points = torch.randn(M, 3)\n",
    "dataset_points = torch.randn(N, 3)\n",
    "\n",
    "knn_dist, knn_indices = find_knn_general(query_points, dataset_points, K)\n",
    "print(knn_dist.shape)\n",
    "print(knn_indices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbdafed",
   "metadata": {},
   "source": [
    "### 2. k-Nearest Neighbor Linear Interpolation\n",
    "- Input: dataset points (N, 3) with the corresponding features (N, C), query points (M, 3), the number of neighbors K\n",
    "- Output: Interpolated query features (M, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6715b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_knn(query_points, dataset_points, dataset_features, k):\n",
    "    M = len(query_points)\n",
    "    N, C = dataset_features.shape\n",
    "    \n",
    "    # 1. Find k-nearest neighbor indices and corresponding features\n",
    "    knn_dist, knn_indices = find_knn_general(query_points, dataset_points, k)\n",
    "    knn_dataset_features = dataset_features[knn_indices.view(-1)].view(M, k, C)\n",
    "    \n",
    "    # 3. Calculate interpolation wegihts\n",
    "    knn_dist_recip = 1. / (knn_dist + 1e-8) # (M, k)\n",
    "    denom = knn_dist_recip.sum(dim=-1, keepdim=True) # (M, 1)\n",
    "    weights = knn_dist_recip / denom # (M, k)\n",
    "    \n",
    "    # 4. Linear interpolation\n",
    "    weighted_features = weights.view(M, k, 1) * knn_dataset_features # (M, k, C)\n",
    "    interpolated_features = weighted_features.sum(dim=1) # (M, C)\n",
    "    \n",
    "    return interpolated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab9adc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 32])\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "M = 25\n",
    "K = 3\n",
    "C = 32\n",
    "\n",
    "query_points = torch.randn(M, 3)\n",
    "dataset_points = torch.randn(N, 3)\n",
    "dataset_features = torch.randn(N, C)\n",
    "\n",
    "interpolated_features = interpolate_knn(query_points, dataset_points, dataset_features, K)\n",
    "print(interpolated_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a7e85",
   "metadata": {},
   "source": [
    "### 3. Farthest Point Sampling\n",
    "- Input: points (N, 3), the number of samples M\n",
    "- Output: sampled_indices (M,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faf5b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b48e7d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def farthest_point_sampling(points, num_samples):\n",
    "    N = len(points)\n",
    "    \n",
    "    # 1. Initialization\n",
    "    sampled_indices = torch.zeros(num_samples, dtype=torch.long)\n",
    "    distance = torch.ones(N,) * 1e10\n",
    "    farthest_idx = random.randint(0, N)\n",
    "    \n",
    "    # 2. Iteratively sample the farthest points\n",
    "    for i in range(num_samples):\n",
    "        # 2-1. Sample the farthest point\n",
    "        sampled_indices[i] = farthest_idx\n",
    "        \n",
    "        # 2-2. Compute distances between the sampled point and other (remaining) points\n",
    "        centroid = points[farthest_idx].view(1, 3)\n",
    "        delta = points - centroid\n",
    "        dist = torch.sum(delta ** 2, dim=-1) # (N,)\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        \n",
    "        # 2-3. Sample the next farthest point\n",
    "        farthest_idx = torch.max(distance, -1)[1]\n",
    "\n",
    "    return sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c03da545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25])\n",
      "torch.Size([25, 3])\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "M = 25\n",
    "\n",
    "points = torch.randn(N, 3)\n",
    "sampled_indices = farthest_point_sampling(points, M)\n",
    "print(sampled_indices.shape)\n",
    "sampled_points = points[sampled_indices]\n",
    "print(sampled_points.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2b4ed3",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4e352a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30d3357",
   "metadata": {},
   "source": [
    "### 1. Point Transformer Layer (Block)\n",
    "- Input: points (N, 3), the corresponding features (N, C_in), the number of neighbors K\n",
    "- Output: the output features (N, C_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "577d1b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointTransformerLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, k):\n",
    "        super(PointTransformerLayer, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.k = k\n",
    "        \n",
    "        self.linear_q = nn.Linear(in_channels, out_channels, bias=False)\n",
    "        self.linear_k = nn.Linear(in_channels, out_channels, bias=False)\n",
    "        self.linear_v = nn.Linear(in_channels, out_channels, bias=False)\n",
    "        \n",
    "        self.mlp_attn = nn.Sequential(\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(out_channels, out_channels),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(out_channels, out_channels)\n",
    "        )\n",
    "        self.mlp_pos = nn.Sequential(\n",
    "            nn.Linear(3, 3),\n",
    "            nn.BatchNorm1d(3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(3, out_channels)\n",
    "        )\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, points, features):\n",
    "        N = len(points)\n",
    "        \n",
    "        # 1. Query, key, and value projections\n",
    "        f_q = self.linear_q(features) # (N, C_out)\n",
    "        f_k = self.linear_k(features) # (N, C_out)\n",
    "        f_v = self.linear_v(features) # (N, C_out)\n",
    "        \n",
    "        # 2. Find kNN for local self-attention\n",
    "        knn_dist, knn_indices = find_knn(points, self.k) # (N, k)\n",
    "        knn_points = points[knn_indices.view(-1)].view(N, self.k, 3)\n",
    "        knn_k = f_k[knn_indices.view(-1)].view(N, self.k, self.out_channels)\n",
    "        knn_v = f_v[knn_indices.view(-1)].view(N, self.k, self.out_channels)\n",
    "        \n",
    "        # 3. Calculate the relative positional encoding\n",
    "        rel_pos = points.view(N, 1, 3) - knn_points # (N, k, 3)\n",
    "        rel_pos_enc = self.mlp_pos(rel_pos.view(-1, 3)).view(N, self.k, -1) # (N, k, C_out)\n",
    "        \n",
    "        # 4. Vector similarity\n",
    "        vec_sim = f_q.view(N, 1, self.out_channels) - knn_k + rel_pos_enc\n",
    "        weights = self.mlp_attn(vec_sim.view(-1, self.out_channels)).view(N, self.k, self.out_channels)\n",
    "        weights = self.softmax(weights) # (N, k, C_out)\n",
    "        \n",
    "        # 5. Weighted sum\n",
    "        weighted_knn_v = weights * (knn_v + rel_pos_enc) # (N, k, C_out)\n",
    "        out_features = weighted_knn_v.sum(dim=1) # (N, C_out)\n",
    "        \n",
    "        return out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a48e2d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 64])\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "C_in = 32\n",
    "C_out = 64\n",
    "K = 7\n",
    "\n",
    "points = torch.randn(N, 3)\n",
    "features = torch.randn(N, C_in)\n",
    "pt_layer = PointTransformerLayer(C_in, C_out, K)\n",
    "\n",
    "out_features = pt_layer(points, features)\n",
    "print(out_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c330fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointTransformerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels, k):\n",
    "        super(PointTransformerBlock, self).__init__()\n",
    "        self.linear_in = nn.Linear(channels, channels)\n",
    "        self.pt_layer = PointTransformerLayer(channels, channels, k)\n",
    "        self.linear_out = nn.Linear(channels, channels)\n",
    "        \n",
    "    def forward(self, points, features):\n",
    "        out_features = self.linear_in(features)\n",
    "        out_features = self.pt_layer(points, out_features)\n",
    "        out_features = self.linear_out(out_features)\n",
    "        out_features += features\n",
    "        \n",
    "        return out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64560113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 32])\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "C = 32\n",
    "\n",
    "K = 7\n",
    "\n",
    "points = torch.randn(N, 3)\n",
    "features = torch.randn(N, C)\n",
    "pt_block = PointTransformerBlock(C, K)\n",
    "\n",
    "out_features = pt_block(points, features)\n",
    "print(out_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8736891c",
   "metadata": {},
   "source": [
    "### 2. TransitionDown\n",
    "- Input: points (N, 3), the corresponding features (N, C), the number of samples M, the number of neighbors K\n",
    "- Output: the sampled points (M, 3) and the corresponding features (M, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03d4f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionDown(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels, num_samples, k):\n",
    "        super(TransitionDown, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.num_samples = num_samples\n",
    "        self.k = k\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(channels, channels, bias=False),\n",
    "            nn.BatchNorm1d(channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels, channels, bias=False),\n",
    "            nn.BatchNorm1d(channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, points, features):\n",
    "        N = len(points)\n",
    "        \n",
    "        # 1. Farthest point sampling\n",
    "        sampled_indices = farthest_point_sampling(points, self.num_samples)\n",
    "        sampled_points = points[sampled_indices]\n",
    "        \n",
    "        # 2. kNN search\n",
    "        knn_dist, knn_indices = find_knn_general(sampled_points, points, self.k) # (M, K)\n",
    "        \n",
    "        # 3. MLP\n",
    "        knn_features = features[knn_indices.view(-1)] # (M*K, C)\n",
    "        out_knn_features = self.mlp(knn_features)\n",
    "        out_knn_features = out_knn_features.view(self.num_samples, self.k, -1)\n",
    "        \n",
    "        # 4. Local max pooling\n",
    "        out_features = out_knn_features.max(dim=1)[0]\n",
    "        \n",
    "        return sampled_points, out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a0b6e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 3])\n",
      "torch.Size([25, 32])\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "C = 32\n",
    "M = 25\n",
    "K = 7\n",
    "\n",
    "points = torch.randn(N, 3)\n",
    "features = torch.randn(N, C)\n",
    "td_module = TransitionDown(C, M, K)\n",
    "\n",
    "down_points, down_features = td_module(points, features)\n",
    "print(down_points.shape)\n",
    "print(down_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7205aa0c",
   "metadata": {},
   "source": [
    "### 3. TransitionUp\n",
    "- Input: up_points (N, 3), up_features (N, C_up), down_points (M, 3), and down_features (M, C_down)\n",
    "- Output: out_features (N, C_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17936ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionUp(nn.Module):\n",
    "    \n",
    "    def __init__(self, up_channels, down_channels, out_channels):\n",
    "        super(TransitionUp, self).__init__()\n",
    "        self.linear_up = nn.Linear(up_channels, out_channels)\n",
    "        self.linear_down = nn.Linear(down_channels, out_channels)\n",
    "        \n",
    "    def forward(self, up_points, up_features, down_points, down_features):\n",
    "        # 1. Feed-forward with the down linear layer\n",
    "        down_f = self.linear_down(down_features)\n",
    "        \n",
    "        # 2. Interpolation\n",
    "        interp_f = interpolate_knn(up_points, down_points, down_f, 3) # (N, C_out)\n",
    "        \n",
    "        # 3. Skip-connection\n",
    "        out_f = interp_f + self.linear_up(up_features)\n",
    "        \n",
    "        return out_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f04f144f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 128])\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "M = 25\n",
    "C_up = 32\n",
    "C_down = 64\n",
    "C_out = 128\n",
    "\n",
    "up_points = torch.randn(N, 3)\n",
    "up_features = torch.randn(N, C_up)\n",
    "down_points = torch.randn(M, 3)\n",
    "down_features = torch.randn(M, C_down)\n",
    "tu_module = TransitionUp(C_up, C_down, C_out)\n",
    "\n",
    "out_features = tu_module(up_points, up_features, down_points, down_features)\n",
    "print(out_features.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
