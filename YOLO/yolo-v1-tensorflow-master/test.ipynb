{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWHWHpnW8-30","executionInfo":{"status":"ok","timestamp":1663394800426,"user_tz":-540,"elapsed":14857,"user":{"displayName":"김희원","userId":"13562236615599718077"}},"outputId":"dfecf1eb-3101-4417-84b8-a9f366c82296"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/Colab_Notebooks/YOLO/yolo-v1-tensorflow-master/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Js_zXurl9AuT","executionInfo":{"status":"ok","timestamp":1663394800895,"user_tz":-540,"elapsed":471,"user":{"displayName":"김희원","userId":"13562236615599718077"}},"outputId":"e5d57211-a8a8-45f5-b7de-6e87cef86f90"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab_Notebooks/YOLO/yolo-v1-tensorflow-master\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"uAhjbOiMTdby","executionInfo":{"status":"ok","timestamp":1663394806653,"user_tz":-540,"elapsed":5760,"user":{"displayName":"김희원","userId":"13562236615599718077"}}},"outputs":[],"source":["import os\n","import cv2\n","import argparse\n","import numpy as np\n","import tensorflow as tf\n","import yolo.config as cfg\n","from yolo.yolo_net import YOLONet\n","from utils.timer import Timer\n","\n","\n","\n","\n","  "]},{"cell_type":"code","source":["class Detector(object):\n","\n","    def __init__(self, net, weight_file):\n","       \n","        self.net = net  # yolo网络\n","        self.weights_file = weight_file  \n","\n","        self.classes = cfg.CLASSES \n","        self.num_class = len(self.classes)  \n","        self.image_size = cfg.IMAGE_SIZE  \n","        self.cell_size = cfg.CELL_SIZE  \n","        self.boxes_per_cell = cfg.BOXES_PER_CELL  \n","        self.threshold = cfg.THRESHOLD  \n","        self.iou_threshold = cfg.IOU_THRESHOLD  \n","\n","       \n","        self.boundary1 = self.cell_size * self.cell_size * self.num_class\n","        self.boundary2 = self.boundary1 + \\\n","                         self.cell_size * self.cell_size * self.boxes_per_cell\n","\n","      \n","        self.sess = tf.Session()\n","        self.sess.run(tf.global_variables_initializer())\n","\n","        # 恢复模型\n","        print('Restoring weights from: ' + self.weights_file)\n","        self.saver = tf.train.Saver()\n","        self.saver.restore(self.sess, self.weights_file)\n","\n","    def draw_result(self, img, result):\n","        for i in range(len(result)):\n","            x = int(result[i][1])\n","            y = int(result[i][2])\n","            w = int(result[i][3] / 2)\n","            h = int(result[i][4] / 2)\n","            cv2.rectangle(img, (x - w, y - h), (x + w, y + h), (0, 255, 0), 2)\n","            cv2.rectangle(img, (x - w, y - h - 20),\n","                          (x + w, y - h), (125, 125, 125), -1)\n","            lineType = cv2.LINE_AA if cv2.__version__ > '3' else cv2.CV_AA\n","            cv2.putText(\n","                img, result[i][0] + ' : %.2f' % result[i][5],\n","                (x - w + 5, y - h - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n","                (0, 0, 0), 1, lineType)\n","\n","    def detect(self, img):\n","       \n","        img_h, img_w, _ = img.shape \n","        inputs = cv2.resize(img, (self.image_size, self.image_size))  \n","        inputs = cv2.cvtColor(inputs, cv2.COLOR_BGR2RGB).astype(np.float32) \n","        inputs = (inputs / 255.0) * 2.0 - 1.0  \n","        inputs = np.reshape(inputs, (1, self.image_size, self.image_size, 3))  \n","        result = self.detect_from_cvmat(inputs)[0]  \n","\n","    \n","        for i in range(len(result)):\n","         \n","            result[i][1] *= (1.0 * img_w / self.image_size)\n","            result[i][2] *= (1.0 * img_h / self.image_size)\n","            result[i][3] *= (1.0 * img_w / self.image_size)\n","            result[i][4] *= (1.0 * img_h / self.image_size)\n","\n","        return result\n","\n","    def detect_from_cvmat(self, inputs):\n","  \n","        net_output = self.sess.run(self.net.logits,\n","                                   feed_dict={self.net.images: inputs})\n","        results = []\n","       \n","        for i in range(net_output.shape[0]):\n","            results.append(self.interpret_output(net_output[i]))\n","\n","        # 返回处理后的结果\n","        return results\n","\n","    def interpret_output(self, output):\n","       \n","        probs = np.zeros((self.cell_size, self.cell_size,\n","                          self.boxes_per_cell, self.num_class))  # [7,7,2,20]\n","        class_probs = np.reshape(\n","            output[0:self.boundary1],\n","            (self.cell_size, self.cell_size, self.num_class))  # 类别概率 [7,7,20]\n","        scales = np.reshape(\n","            output[self.boundary1:self.boundary2],\n","            (self.cell_size, self.cell_size, self.boxes_per_cell))  # 置信度 [7,7,2]\n","        boxes = np.reshape(\n","            output[self.boundary2:],\n","            (self.cell_size, self.cell_size, self.boxes_per_cell, 4))  # 边界框 [7,7,2,4]\n","        offset = np.array(\n","            [np.arange(self.cell_size)] * self.cell_size * self.boxes_per_cell)  # [14,7]  每一行[0,1,2,3,4,5,6]\n","        offset = np.transpose(np.reshape(offset,[self.boxes_per_cell, self.cell_size, self.cell_size]),(1, 2, 0))  # [7,7,2] 每一行都是  [[0,0],[1,1],[2,2],[3,3],[4,4],[5,5],[6,6]]\n","\n","        boxes[:, :, :, 0] += offset  # 目标中心是相对于整个图片的\n","        boxes[:, :, :, 1] += np.transpose(offset, (1, 0, 2))\n","        boxes[:, :, :, :2] = 1.0 * boxes[:, :, :, 0:2] / self.cell_size  # 宽度、高度相对整个图片的\n","        boxes[:, :, :, 2:] = np.square(boxes[:, :, :, 2:])\n","\n","        # 转换成实际的编辑框(没有归一化的)\n","        boxes *= self.image_size\n","\n","        # 遍历每一个边界框的置信度\n","        for i in range(self.boxes_per_cell):\n","            # 遍历每一个类别\n","            for j in range(self.num_class):\n","                # 在测试时，乘以条件类概率和单个盒子的置信度预测，这些分数编码了j类出现在框i中的概率以及预测框拟合目标的程度。\n","                probs[:, :, i, j] = np.multiply(\n","                    class_probs[:, :, j], scales[:, :, i])\n","\n","        # [7,7,2,20] 如果第i个边界框检测到类别j 则[;,;,i,j]=1\n","        filter_mat_probs = np.array(probs >= self.threshold, dtype='bool')\n","        # 返回filter_mat_probs非0值的索引 返回4个List，每个list长度为n  即检测到的边界框的个数\n","        filter_mat_boxes = np.nonzero(filter_mat_probs)\n","        # 获取检测到目标的边界框 [n,4]  n表示边界框的个数\n","        boxes_filtered = boxes[filter_mat_boxes[0],\n","                               filter_mat_boxes[1], filter_mat_boxes[2]]\n","        # 获取检测到目标的边界框的置信度 (n,)\n","        probs_filtered = probs[filter_mat_probs]\n","        # 获取检测到目标的边界框对应的目标类别 (n,)\n","        classes_num_filtered = np.argmax(\n","            filter_mat_probs, axis=3)[\n","            filter_mat_boxes[0], filter_mat_boxes[1], filter_mat_boxes[2]]\n","\n","        # 按置信度倒序排序，返回对应的索引\n","        argsort = np.array(np.argsort(probs_filtered))[::-1]\n","        boxes_filtered = boxes_filtered[argsort]\n","        probs_filtered = probs_filtered[argsort]\n","        classes_num_filtered = classes_num_filtered[argsort]\n","\n","        for i in range(len(boxes_filtered)):\n","            if probs_filtered[i] == 0:\n","                continue\n","            for j in range(i + 1, len(boxes_filtered)):\n","                # 计算n各边界框，两两之间的IoU是否大于阈值，非极大值抑制\n","                if self.iou(boxes_filtered[i], boxes_filtered[j]) > self.iou_threshold:\n","                    probs_filtered[j] = 0.0\n","\n","        # 非极大值抑制后的输出\n","        filter_iou = np.array(probs_filtered > 0.0, dtype='bool')\n","        boxes_filtered = boxes_filtered[filter_iou]\n","        probs_filtered = probs_filtered[filter_iou]\n","        classes_num_filtered = classes_num_filtered[filter_iou]\n","\n","        result = []\n","        # 遍历每一个边界框\n","        for i in range(len(boxes_filtered)):\n","            result.append([self.classes[classes_num_filtered[i]], boxes_filtered[i][0], boxes_filtered[i][1], boxes_filtered[i][2], boxes_filtered[i][3], probs_filtered[i]]) \n","\n","        return result\n","\n","    def iou(self, box1, box2):\n","        \"\"\"\n","        计算两个边界框的IoU\n","\n","        :param box1: 边界框1  [4,]   真实值\n","        :param box2: 边界框2  [4,]   真实值\n","        :return:\n","        \"\"\"\n","        tb = min(box1[0] + 0.5 * box1[2], box2[0] + 0.5 * box2[2]) - \\\n","             max(box1[0] - 0.5 * box1[2], box2[0] - 0.5 * box2[2])\n","        lr = min(box1[1] + 0.5 * box1[3], box2[1] + 0.5 * box2[3]) - \\\n","             max(box1[1] - 0.5 * box1[3], box2[1] - 0.5 * box2[3])\n","        inter = 0 if tb < 0 or lr < 0 else tb * lr\n","        return inter / (box1[2] * box1[3] + box2[2] * box2[3] - inter)\n","\n","    def camera_detector(self, wait=10):\n","        \"\"\"\n","        打开摄像头实时监测\n","        \"\"\"\n","        detect_timer = Timer()  # 测试时间\n","        cap = cv2.VideoCapture(0)\n","        ret, _ = cap.read()  # 读取一帧\n","\n","        while ret:\n","            ret, frame = cap.read()  # 读取一帧\n","            detect_timer.tic()  # 测试其实时间\n","            result = self.detect(frame)  # 测试结束时间\n","            detect_timer.toc()\n","            print('Average detecting time: {:.3f}s'.format(detect_timer.average_time))\n","\n","            self.draw_result(frame, result)  # 绘制边界框，以及添加附加信息\n","            cv2.imshow('Camera', frame)  # 显示\n","            cv2.waitKey(wait)\n","\n","            ret, frame = cap.read()\n","\n","    def image_detector(self, imname, wait=0):\n","        \"\"\"\n","        目标检测\n","\n","        :param imname: 测试图片路径\n","        :param wait:\n","        \"\"\"\n","        detect_timer = Timer()  # 检测时间\n","        image = cv2.imread(imname)  # 读取图片\n","\n","        detect_timer.tic()  # 检测的起始时间\n","        result = self.detect(image)  # 开始检测\n","        detect_timer.toc()  # 检测的结束时间\n","        print('Average detecting time: {:.3f}s'.format(detect_timer.average_time))\n","\n","        self.draw_result(image, result)  # 绘制检测结果\n","        cv2.imshow('Image', image)\n","        cv2.waitKey(wait)\n","\n","\n","\n"],"metadata":{"id":"6WH7euxDTnTr","executionInfo":{"status":"ok","timestamp":1663395121288,"user_tz":-540,"elapsed":324,"user":{"displayName":"김희원","userId":"13562236615599718077"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["\n","def main():\n","    weights=\"YOLO_small.ckpt\"\n","    weight_dir = 'weights'\n","    data_dir = \"data\"\n","\n","    yolo = YOLONet(False)  # 创建YOLO网络对象\n","    weight_file = os.path.join(data_dir, weight_dir, weights)  # 加载检查点文件\n","    detector = Detector(yolo, weight_file)  # 创建测试对象\n","\n","    # detect from camera\n","    # cap = cv2.VideoCapture(-1)\n","    # detector.camera_detector(cap)\n","\n","    # detect from image file\n","    # imname = 'test/person.jpg'\n","    # detector.image_detector(imname)\n","\n","    # detect from camera\n","    # GTX 1060 25FPS\n","    detector.camera_detector()\n","\n"],"metadata":{"id":"ThWr9Oo4-e3g","executionInfo":{"status":"ok","timestamp":1663395131272,"user_tz":-540,"elapsed":308,"user":{"displayName":"김희원","userId":"13562236615599718077"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"id":"HYDTDKkTBFE_","executionInfo":{"status":"error","timestamp":1663395133799,"user_tz":-540,"elapsed":335,"user":{"displayName":"김희원","userId":"13562236615599718077"}},"outputId":"1cb68d18-ab25-4d93-cb40-d95830d6c383"},"execution_count":10,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-fd1bc4a06f3a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0myolo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLONet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 创建YOLO网络对象\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mweight_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 加载检查点文件\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myolo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_file\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 创建测试对象\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Colab_Notebooks/YOLO/yolo-v1-tensorflow-master/yolo/yolo_net.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, is_training)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."]}]}]}