{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tscW8jR4UdOT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import yolo.config as cfg\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slim = tf.contrib.slim\n",
        "\n",
        "\n",
        "class YOLONet(object):\n",
        "\n",
        "    def __init__(self, is_training=True):\n",
        "       \n",
        "        self.classes = cfg.CLASSES  # 类别\n",
        "        self.num_class = len(self.classes)  # 类别数量20\n",
        "        self.image_size = cfg.IMAGE_SIZE  # 图像尺寸448\n",
        "        self.cell_size = cfg.CELL_SIZE  # cell尺寸7\n",
        "        self.boxes_per_cell = cfg.BOXES_PER_CELL  # 每个grid cell负责的box数量，文论中为2\n",
        "        self.output_size = (self.cell_size * self.cell_size) * \\\n",
        "                           (self.num_class + self.boxes_per_cell * 5)  # 输出尺寸(7*7)*(20+2*5)\n",
        "        self.scale = 1.0 * self.image_size / self.cell_size  # 图像尺寸和cell尺寸比例\n",
        "        self.boundary1 = self.cell_size * self.cell_size * self.num_class  # 7*7*20\n",
        "        self.boundary2 = self.boundary1 + \\\n",
        "                         self.cell_size * self.cell_size * self.boxes_per_cell  # 7*7*20 + 7*7*2\n",
        "\n",
        "        self.object_scale = cfg.OBJECT_SCALE  # 值为1.0\n",
        "        self.noobject_scale = cfg.NOOBJECT_SCALE  # 值为1.0\n",
        "        self.class_scale = cfg.CLASS_SCALE  # 值为2.0\n",
        "        self.coord_scale = cfg.COORD_SCALE  # 值为5.0\n",
        "\n",
        "        self.learning_rate = cfg.LEARNING_RATE  # 学习速率LEARNING_RATE = 0.0001\n",
        "        self.batch_size = cfg.BATCH_SIZE  # BATCH_SIZE = 45\n",
        "        self.alpha = cfg.ALPHA  # ALPHA = 0.1\n",
        "\n",
        "        self.offset = np.transpose(np.reshape(np.array(\n",
        "            [np.arange(self.cell_size)] * self.cell_size * self.boxes_per_cell),\n",
        "            (self.boxes_per_cell, self.cell_size, self.cell_size)), (1, 2, 0))  # 偏置 形状为 (7,7,2)\n",
        "\n",
        "        self.images = tf.placeholder(\n",
        "            tf.float32, [None, self.image_size, self.image_size, 3],\n",
        "            name='images')  # 输入图片 (None,448,448,3)\n",
        "        self.logits = self.build_network(\n",
        "            self.images, num_outputs=self.output_size, alpha=self.alpha,\n",
        "            is_training=is_training)  # 构建网络 获取网络输出 形状为 (None,1470)\n",
        "\n",
        "        if is_training:\n",
        "            self.labels = tf.placeholder(\n",
        "                tf.float32,\n",
        "                [None, self.cell_size, self.cell_size, 5 + self.num_class])  # 标签 (None,7,7,25)\n",
        "            self.loss_layer(self.logits, self.labels)  # 损失函数\n",
        "            self.total_loss = tf.losses.get_total_loss()  # 加入权重之后的损失函数\n",
        "            tf.summary.scalar('total_loss', self.total_loss)  # 将损失以标量形式显示 命名为total_loss\n",
        "\n",
        "    def build_network(self,\n",
        "                      images,\n",
        "                      num_outputs,\n",
        "                      alpha,\n",
        "                      keep_prob=0.5,\n",
        "                      is_training=True,\n",
        "                      scope='yolo'):\n",
        "        \"\"\"\n",
        "            构建YOLO网络\n",
        "\n",
        "            args:\n",
        "                images：输入图片占位符 [None,image_size,image_size,3]  这里是[None,448,448,3]\n",
        "                num_outputs：标量，网络输出节点数 1470\n",
        "                alpha：泄露修正线性激活函数 系数0.1\n",
        "                keep_prob：弃权 保留率\n",
        "                is_training：训练？\n",
        "                scope：命名空间名\n",
        "\n",
        "            return：\n",
        "                返回网络最后一层，激活函数处理之前的值  形状[None,1470]\n",
        "        \"\"\"\n",
        "        with tf.variable_scope(scope):  # 定义变量命名空间\n",
        "            with slim.arg_scope(  # 定义共享参数 使用L2正则化\n",
        "                    [slim.conv2d, slim.fully_connected],\n",
        "                    activation_fn=leaky_relu(alpha),\n",
        "                    weights_regularizer=slim.l2_regularizer(0.0005),\n",
        "                    weights_initializer=tf.truncated_normal_initializer(0.0, 0.01)\n",
        "            ):\n",
        "                net = tf.pad(\n",
        "                    images, np.array([[0, 0], [3, 3], [3, 3], [0, 0]]),\n",
        "                    name='pad_1')  # pad_1填充成 (None,454,454,3)\n",
        "                # TODO 替换slim成keras\n",
        "                net = slim.conv2d(net, 64, 7, 2, padding='VALID', scope='conv_2')\n",
        "                net = slim.max_pool2d(net, 2, padding='SAME', scope='pool_3')\n",
        "                net = slim.conv2d(net, 192, 3, scope='conv_4')\n",
        "                net = slim.max_pool2d(net, 2, padding='SAME', scope='pool_5')\n",
        "                net = slim.conv2d(net, 128, 1, scope='conv_6')\n",
        "                net = slim.conv2d(net, 256, 3, scope='conv_7')\n",
        "                net = slim.conv2d(net, 256, 1, scope='conv_8')\n",
        "                net = slim.conv2d(net, 512, 3, scope='conv_9')\n",
        "                net = slim.max_pool2d(net, 2, padding='SAME', scope='pool_10')\n",
        "                net = slim.conv2d(net, 256, 1, scope='conv_11')\n",
        "                net = slim.conv2d(net, 512, 3, scope='conv_12')\n",
        "                net = slim.conv2d(net, 256, 1, scope='conv_13')\n",
        "                net = slim.conv2d(net, 512, 3, scope='conv_14')\n",
        "                net = slim.conv2d(net, 256, 1, scope='conv_15')\n",
        "                net = slim.conv2d(net, 512, 3, scope='conv_16')\n",
        "                net = slim.conv2d(net, 256, 1, scope='conv_17')\n",
        "                net = slim.conv2d(net, 512, 3, scope='conv_18')\n",
        "                net = slim.conv2d(net, 512, 1, scope='conv_19')\n",
        "                net = slim.conv2d(net, 1024, 3, scope='conv_20')\n",
        "                net = slim.max_pool2d(net, 2, padding='SAME', scope='pool_21')\n",
        "                net = slim.conv2d(net, 512, 1, scope='conv_22')\n",
        "                net = slim.conv2d(net, 1024, 3, scope='conv_23')\n",
        "                net = slim.conv2d(net, 512, 1, scope='conv_24')\n",
        "                net = slim.conv2d(net, 1024, 3, scope='conv_25')\n",
        "                net = slim.conv2d(net, 1024, 3, scope='conv_26')\n",
        "                net = tf.pad(\n",
        "                    net, np.array([[0, 0], [1, 1], [1, 1], [0, 0]]),\n",
        "                    name='pad_27')\n",
        "                net = slim.conv2d(net, 1024, 3, 2, padding='VALID', scope='conv_28')\n",
        "                net = slim.conv2d(net, 1024, 3, scope='conv_29')\n",
        "                net = slim.conv2d(net, 1024, 3, scope='conv_30')\n",
        "                net = tf.transpose(net, [0, 3, 1, 2], name='trans_31')\n",
        "                net = slim.flatten(net, scope='flat_32')\n",
        "                net = slim.fully_connected(net, 512, scope='fc_33')\n",
        "                net = slim.fully_connected(net, 4096, scope='fc_34')\n",
        "                net = slim.dropout(\n",
        "                    net, keep_prob=keep_prob, is_training=is_training,\n",
        "                    scope='dropout_35')\n",
        "                net = slim.fully_connected(net, num_outputs, activation_fn=None, scope='fc_36')\n",
        "        return net\n",
        "\n",
        "    def calc_iou(self, boxes1, boxes2, scope='iou'):\n",
        "        \"\"\"calculate ious\n",
        "        这个函数的主要作用是计算两个 bounding box 之间的 IoU。输入是两个 5 维的bounding box,输出的两个 bounding Box 的IoU\n",
        "        Args:\n",
        "          boxes1: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n",
        "          boxes2: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4] ===> (x_center, y_center, w, h)\n",
        "          注意这里的参数x_center, y_center, w, h都是归一到[0,1]之间的，分别表示预测边界框的中心相对整张图片的坐标，宽和高\n",
        "        Return:\n",
        "          iou: 4-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
        "        \"\"\"\n",
        "        with tf.variable_scope(scope):\n",
        "            # transform (x_center, y_center, w, h) to (x1, y1, x2, y2)\n",
        "            # 把以前的中心点坐标和长和宽转换成了左上角和右下角的两个点的坐标\n",
        "            boxes1_t = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0,\n",
        "                                 boxes1[..., 1] - boxes1[..., 3] / 2.0,\n",
        "                                 boxes1[..., 0] + boxes1[..., 2] / 2.0,\n",
        "                                 boxes1[..., 1] + boxes1[..., 3] / 2.0],\n",
        "                                axis=-1)\n",
        "\n",
        "            boxes2_t = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0,\n",
        "                                 boxes2[..., 1] - boxes2[..., 3] / 2.0,\n",
        "                                 boxes2[..., 0] + boxes2[..., 2] / 2.0,\n",
        "                                 boxes2[..., 1] + boxes2[..., 3] / 2.0],\n",
        "                                axis=-1)\n",
        "\n",
        "            # calculate the left up point & right down point\n",
        "            # 注意此坐标系 坐标原点 为左上角！！！\n",
        "            # lu和rd就是分别求两个框相交的矩形的左上角的坐标和右下角的坐标，因为对于左上角，\n",
        "            # 选择的是x和y较大的，而右下角是选择较小的，可以想想两个矩形框相交是不是这中情况\n",
        "            lu = tf.maximum(boxes1_t[..., :2], boxes2_t[..., :2])  # lu(left up) 两个框相交的矩形的左上角(x1,y1)\n",
        "            rd = tf.minimum(boxes1_t[..., 2:], boxes2_t[..., 2:])  # rd(right down) 两个框相交的矩形的右下角(x2,y2)\n",
        "\n",
        "            # intersection\n",
        "            # 这个就是求相交矩形的长和宽，所以有rd-lu，相当于x1-x2和y1-y2，\n",
        "            # 之所以外面还要加一个tf.maximum是因为删除那些不合理的框，比如两个框没交集，\n",
        "            # 就会出现左上角坐标比右下角还大。\n",
        "            intersection = tf.maximum(0.0, rd - lu)\n",
        "            # inter_square这个就是求面积了，就是长乘以宽。\n",
        "            inter_square = intersection[..., 0] * intersection[..., 1]\n",
        "\n",
        "            # calculate the boxs1 square and boxs2 square\n",
        "            # square1和square2这个就是求面积了，因为之前是中心点坐标和长和宽，所以这里直接用长和宽\n",
        "            square1 = boxes1[..., 2] * boxes1[..., 3]\n",
        "            square2 = boxes2[..., 2] * boxes2[..., 3]\n",
        "\n",
        "            # union_square就是就两个框的交面积，因为如果两个框的面积相加，那就会重复了相交的部分，\n",
        "            # 所以减去相交的部分，外面有个tf.maximum这个就是保证相交面积不为0,因为后面要做分母。\n",
        "            union_square = tf.maximum(square1 + square2 - inter_square, 1e-10)\n",
        "\n",
        "        # 最后有一个tf.clip_by_value,这个是将如果你的交并比大于1,那么就让它等于1,如果小于0,那么就\n",
        "        # 让他变为0,因为交并比在0-1之间。\n",
        "        return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)\n",
        "\n",
        "    def loss_layer(self, predicts, labels, scope='loss_layer'):\n",
        "        \"\"\"\n",
        "        计算预测和标签之间的损失函数\n",
        "            args：\n",
        "                predicts：Yolo网络的输出 形状[None,1470]\n",
        "                0：7*7*20：表示预测类别\n",
        "                7*7*20:7*7*20 + 7*7*2:表示预测置信度，即预测的边界框与实际边界框之间的IOU\n",
        "                7*7*20 + 7*7*2：1470：预测边界框    目标中心是相对于当前格子的，宽度和高度的开根号是相对当前整张图像的(归一化的)\n",
        "                labels：标签值 形状[None,7,7,25]\n",
        "                0:1：置信度，表示这个地方是否有目标\n",
        "                1:5：目标边界框  目标中心，宽度和高度(没有归一化)\n",
        "                5:25：目标的类别\n",
        "        \"\"\"\n",
        "        with tf.variable_scope(scope):\n",
        "            # 将网络输出分离为类别和置信度以及边界框的大小，输出维度为7*7*20 + 7*7*2 + 7*7*2*4=1470\n",
        "            predict_classes = tf.reshape(\n",
        "                predicts[:, :self.boundary1],\n",
        "                [self.batch_size, self.cell_size, self.cell_size, self.num_class])  # 预测每个格子目标的类别 形状[45,7,7,20]\n",
        "            predict_scales = tf.reshape(\n",
        "                predicts[:, self.boundary1:self.boundary2],\n",
        "                [self.batch_size, self.cell_size, self.cell_size, self.boxes_per_cell])  # 预测每个格子中两个边界框的置信度 形状[45,7,7,2]\n",
        "            predict_boxes = tf.reshape(\n",
        "                predicts[:, self.boundary2:],\n",
        "                [self.batch_size, self.cell_size, self.cell_size, self.boxes_per_cell, 4])\n",
        "            # 预测每个格子中的两个边界框，(x,y)表示边界框相对于格子边界框的中心 w,h的开根号相对于整个图片  形状[45,7,7,2,4]\n",
        "            response = tf.reshape(\n",
        "                labels[..., 0],\n",
        "                [self.batch_size, self.cell_size, self.cell_size, 1])  # 标签的置信度,表示这个地方是否有框 形状[45,7,7,1]\n",
        "            boxes = tf.reshape(\n",
        "                labels[..., 1:5],\n",
        "                [self.batch_size, self.cell_size, self.cell_size, 1, 4])  # 标签的边界框 (x,y)表示边界框相对于整个图片的中心 形状[45,7,7,1，4]\n",
        "            boxes = tf.tile(\n",
        "                boxes,\n",
        "                [1, 1, 1, self.boxes_per_cell, 1]) / self.image_size  # 标签的边界框 归一化后 张量沿着axis=3重复两边，扩充后[45,7,7,2,4]\n",
        "            classes = labels[..., 5:]\n",
        "\n",
        "            \"\"\"\n",
        "            predict_boxes_tran：offset变量用于把预测边界框predict_boxes中的坐标中心(x,y)由相对当前格子转换为相对当前整个图片\n",
        "            offset，这个是构造的[7,7,2]矩阵，每一行都是[7,2]的矩阵，值为[[0,0],[1,1],[2,2],[3,3],[4,4],[5,5],[6,6]]\n",
        "            这个变量是为了将每个cell的坐标对齐，后一个框比前一个框要多加1\n",
        "            比如我们预测了cell_size的每个中心点坐标，那么我们这个中心点落在第几个cell_size\n",
        "            就对应坐标要加几，这个用法比较巧妙，构造了这样一个数组，让他们对应位置相加\n",
        "            \"\"\"\n",
        "            # offset shape为[1,7,7,2]  如果忽略axis=0，则每一行都是  [[0,0],[1,1],[2,2],[3,3],[4,4],[5,5],[6,6]]\n",
        "            offset = tf.reshape(\n",
        "                tf.constant(self.offset, dtype=tf.float32),\n",
        "                [1, self.cell_size, self.cell_size, self.boxes_per_cell])\n",
        "            offset = tf.tile(offset, [self.batch_size, 1, 1, 1])\n",
        "            ''\n",
        "            # shape为[45,7,7,2]  如果忽略axis=0 第i行为[[i,i],[i,i],[i,i],[i,i],[i,i],[i,i],[i,i]]\n",
        "            offset_tran = tf.transpose(offset, (0, 2, 1, 3))\n",
        "\n",
        "            # shape为[45,7,7,2,4]  计算每个格子中的预测边界框坐标(x,y)相对于整个图片的位置  而不是相对当前格子\n",
        "            # 假设当前格子为(3,3)，当前格子的预测边界框为(x0,y0)，则计算坐标(x,y) = ((x0,y0)+(3,3))/7\n",
        "            predict_boxes_tran = tf.stack(\n",
        "                [(predict_boxes[..., 0] + offset) / self.cell_size,\n",
        "                 (predict_boxes[..., 1] + offset_tran) / self.cell_size,\n",
        "                 tf.square(predict_boxes[..., 2]),\n",
        "                 tf.square(predict_boxes[..., 3])], axis=-1)\n",
        "\n",
        "            # 计算每个格子预测边界框与真实边界框之间的IOU  [45,7,7,2]\n",
        "            iou_predict_truth = self.calc_iou(predict_boxes_tran, boxes)\n",
        "\n",
        "            # calculate I tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
        "            # 这个是求论文中的1ijobj参数，[45,7,7,2]     1ijobj：表示网格单元i的第j个编辑框预测器’负责‘该预测\n",
        "            # 先计算每个框交并比最大的那个，因为我们知道，YOLO每个格子预测两个边界框，一个类别。在训练时，每个目标只需要\n",
        "            # 一个预测器来负责，我们指定一个预测器\"负责\"，根据哪个预测器与真实值之间具有当前最高的IOU来预测目标。\n",
        "            # 所以object_mask就表示每个格子中的哪个边界框负责该格子中目标预测？哪个边界框取值为1，哪个边界框就负责目标预测\n",
        "            # 当格子中的确有目标时，取值为[1,1]，[1,0],[0,1]\n",
        "            # 比如某一个格子的值为[1,0]，表示第一个边界框负责该格子目标的预测  [0,1]：表示第二个边界框负责该格子目标的预测\n",
        "            # 当格子没有目标时，取值为[0,0]\n",
        "            object_mask = tf.reduce_max(iou_predict_truth, 3, keep_dims=True)\n",
        "            object_mask = tf.cast(\n",
        "                (iou_predict_truth >= object_mask), tf.float32) * response\n",
        "\n",
        "            # calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
        "            # noobject_mask就表示每个边界框不负责该目标的置信度，\n",
        "            # 使用tf.onr_like，使得全部为1,再减去有目标的，也就是有目标的对应坐标为1,这样一减，就变为没有的了。[45,7,7,2]\n",
        "            noobject_mask = tf.ones_like(\n",
        "                object_mask, dtype=tf.float32) - object_mask\n",
        "\n",
        "            # boxes_tran 这个就是把之前的坐标换回来(相对整个图像->相对当前格子)，长和宽开方(原因在论文中有说明)，后面求loss就方便。 shape为(4, 45, 7, 7, 2)\n",
        "            boxes_tran = tf.stack(\n",
        "                [boxes[..., 0] * self.cell_size - offset,\n",
        "                 boxes[..., 1] * self.cell_size - offset_tran,\n",
        "                 tf.sqrt(boxes[..., 2]),\n",
        "                 tf.sqrt(boxes[..., 3])], axis=-1)\n",
        "\n",
        "            # class_loss 分类损失，如果目标出现在网格中 response为1，否则response为0  原文代价函数公式第5项\n",
        "            # 该项表名当格子中有目标时，预测的类别越接近实际类别，代价值越小  原文代价函数公式第5项\n",
        "            class_delta = response * (predict_classes - classes)\n",
        "            class_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(tf.square(class_delta), axis=[1, 2, 3]),\n",
        "                name='class_loss') * self.class_scale\n",
        "\n",
        "            # object_loss 有目标物体存在的置信度预测损失   原文代价函数公式第3项\n",
        "            # 该项表名当格子中有目标时，负责该目标预测的边界框的置信度越越接近预测的边界框与实际边界框之间的IOU时，代价值越小\n",
        "            object_delta = object_mask * (predict_scales - iou_predict_truth)\n",
        "            object_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(tf.square(object_delta), axis=[1, 2, 3]),\n",
        "                name='object_loss') * self.object_scale\n",
        "\n",
        "            # noobject_loss  没有目标物体存在的置信度的损失(此时iou_predict_truth为0)  原文代价函数公式第4项\n",
        "            # 该项表名当格子中没有目标时，预测的两个边界框的置信度越接近0，代价值越小\n",
        "            noobject_delta = noobject_mask * predict_scales\n",
        "            noobject_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(tf.square(noobject_delta), axis=[1, 2, 3]),\n",
        "                name='noobject_loss') * self.noobject_scale\n",
        "\n",
        "            # coord_loss 边界框坐标损失 shape 为 [batch_size, 7, 7, 2, 1]  原文代价函数公式1,2项\n",
        "            # 该项表名当格子中有目标时，预测的边界框越接近实际边界框，代价值越小\n",
        "            coord_mask = tf.expand_dims(object_mask, 4)\n",
        "            boxes_delta = coord_mask * (predict_boxes - boxes_tran)\n",
        "            coord_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(tf.square(boxes_delta), axis=[1, 2, 3, 4]),\n",
        "                name='coord_loss') * self.coord_scale\n",
        "\n",
        "            # 将所有损失放在一起\n",
        "            tf.losses.add_loss(class_loss)\n",
        "            tf.losses.add_loss(object_loss)\n",
        "            tf.losses.add_loss(noobject_loss)\n",
        "            tf.losses.add_loss(coord_loss)\n",
        "\n",
        "            # 将每个损失添加到日志记录\n",
        "            tf.summary.scalar('class_loss', class_loss)\n",
        "            tf.summary.scalar('object_loss', object_loss)\n",
        "            tf.summary.scalar('noobject_loss', noobject_loss)\n",
        "            tf.summary.scalar('coord_loss', coord_loss)\n",
        "\n",
        "            tf.summary.histogram('boxes_delta_x', boxes_delta[..., 0])\n",
        "            tf.summary.histogram('boxes_delta_y', boxes_delta[..., 1])\n",
        "            tf.summary.histogram('boxes_delta_w', boxes_delta[..., 2])\n",
        "            tf.summary.histogram('boxes_delta_h', boxes_delta[..., 3])\n",
        "            tf.summary.histogram('iou', iou_predict_truth)\n",
        "\n",
        "\n",
        "def leaky_relu(alpha):\n",
        "    def op(inputs):\n",
        "        return tf.nn.leaky_relu(inputs, alpha=alpha, name='leaky_relu')\n",
        "\n",
        "    return op\n"
      ],
      "metadata": {
        "id": "mpJ_X1EaUkSA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}