{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "import yolo.config as cfg\n",
        "from yolo.yolo_net import YOLONet\n",
        "from utils.timer import Timer\n",
        "from utils.pascal_voc import pascal_voc"
      ],
      "metadata": {
        "id": "A9oseXrmS7yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "slim = tf.contrib.slim\n",
        "\n",
        "\"\"\"\n",
        "训练YOLO网络模型\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class Solver(object):\n",
        "    \"\"\"\n",
        "    求解器的类，用于训练YOLO网络\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, net, data):\n",
        "        \"\"\"\n",
        "        构造函数，加载训练参数\n",
        "\n",
        "        :param net: YOLONet对象\n",
        "        :param data: pascal_voc对象\n",
        "        \"\"\"\n",
        "        self.net = net  # yolo网络\n",
        "        self.data = data  # voc2007数据处理\n",
        "        self.weights_dir = cfg.WEIGHTS_DIR  # 检查点文件存放路径\n",
        "        self.meta_file = cfg.WEIGHTS_META  # META文件名\n",
        "        self.weights_file = cfg.WEIGHTS_FILE  # 检查点文件路径 /data/weight/YOLO_small.ckpt\n",
        "        self.max_iter = cfg.MAX_ITER  # 训练最大迭代次数\n",
        "        self.initial_learning_rate = cfg.LEARNING_RATE  # 初始学习率\n",
        "        self.decay_steps = cfg.DECAY_STEPS  # 退化学习率衰减步数\n",
        "        self.decay_rate = cfg.DECAY_RATE  # 衰减率\n",
        "        self.staircase = cfg.STAIRCASE  # 日志文件保存间隔步\n",
        "        self.summary_iter = cfg.SUMMARY_ITER\n",
        "        self.save_iter = cfg.SAVE_ITER  # 模型保存间隔步\n",
        "        self.output_dir = os.path.join(\n",
        "            cfg.OUTPUT_DIR, datetime.datetime.now().strftime('%Y_%m_%d_%H_%M'))  # 输出文件夹路径\n",
        "        if not os.path.exists(self.output_dir):\n",
        "            os.makedirs(self.output_dir)\n",
        "        self.save_cfg()  # 保存配置信息\n",
        "\n",
        "        self.variable_to_restore = tf.global_variables()  # 创建变量，保存当前迭代次数\n",
        "        # self.saver = tf.train.Saver(self.variable_to_restore, max_to_keep=None)\n",
        "\n",
        "        self.ckpt_file = os.path.join(self.output_dir, 'yolo')  # 指定保存的模型名称\n",
        "        self.summary_op = tf.summary.merge_all()  # 合并所有的summary\n",
        "        self.writer = tf.summary.FileWriter(self.output_dir, flush_secs=60)  # 创建writer，指定日志文件路径，用于写日志文件\n",
        "\n",
        "        self.global_step = tf.train.create_global_step()  # 创建变量，保存当前迭代次数\n",
        "        self.learning_rate = tf.train.exponential_decay(\n",
        "            self.initial_learning_rate, self.global_step, self.decay_steps,\n",
        "            self.decay_rate, self.staircase, name='learning_rate')  # 退化学习率\n",
        "        self.optimizer = tf.train.GradientDescentOptimizer(\n",
        "            learning_rate=self.learning_rate)  # 创建求解器\n",
        "        self.train_op = slim.learning.create_train_op(\n",
        "            self.net.total_loss, self.optimizer, global_step=self.global_step)\n",
        "\n",
        "        gpu_options = tf.GPUOptions()  # 设置GPU使用资源\n",
        "        config = tf.ConfigProto(gpu_options=gpu_options)  # 按需分配GPU使用的资源\n",
        "        self.sess = tf.Session(config=config)\n",
        "        self.sess.run(tf.global_variables_initializer())  # 运行图之前，初始化变量\n",
        "\n",
        "        # 恢复模型\n",
        "        if self.weights_file is not None:\n",
        "            print('Restoring weights from: ' + self.weights_dir)\n",
        "            self.saver = tf.train.import_meta_graph(os.path.join(self.weights_dir, self.meta_file))\n",
        "            self.saver.restore(self.sess, tf.train.latest_checkpoint(self.weights_dir))\n",
        "\n",
        "        self.writer.add_graph(self.sess.graph)  # 将图写入日志文件"
      ],
      "metadata": {
        "id": "v-AHl2GBTHsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9X4_yXeSKcm"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        开始训练\n",
        "        \"\"\"\n",
        "\n",
        "        train_timer = Timer()  # 训练时间\n",
        "        load_timer = Timer()  # 数据集加载时间\n",
        "\n",
        "        # 开始迭代\n",
        "        for step in range(1, self.max_iter + 1):\n",
        "\n",
        "            load_timer.tic()  # 计算每次迭代加载数据的起始时间\n",
        "            images, labels = self.data.get()  # 加载数据集 每次读取batch大小的图片以及图片对应的标签\n",
        "            load_timer.toc()  # 计算这次迭代加载数据集所使用的时间\n",
        "            feed_dict = {self.net.images: images,\n",
        "                         self.net.labels: labels}\n",
        "\n",
        "            # 迭代summary_iter次，保存一次日志文件，迭代summary_iter*10次，输出一次的迭代信息\n",
        "            if step % self.summary_iter == 0:\n",
        "                if step % (self.summary_iter * 10) == 0:\n",
        "\n",
        "                    train_timer.tic()  # 计算每次迭代训练的起始时间\n",
        "                    summary_str, loss, _ = self.sess.run(\n",
        "                        [self.summary_op, self.net.total_loss, self.train_op],\n",
        "                        feed_dict=feed_dict)  # 开始迭代训练，每一次迭代后global_step自加1\n",
        "                    train_timer.toc()\n",
        "\n",
        "                    # 输出信息\n",
        "                    log_str = '{} Epoch: {}, Step: {}, Learning rate: {},Loss: {:5.3f}\\nSpeed: {:.3f}s/iter,' \\\n",
        "                              'Load: {:.3f}s/iter, Remain: {}'.format(datetime.datetime.now(), self.data.epoch,\n",
        "                                                                      int(step),\n",
        "                                                                      round(self.learning_rate.eval(session=self.sess),\n",
        "                                                                            6), loss, train_timer.average_time,\n",
        "                                                                      load_timer.average_time,\n",
        "                                                                      train_timer.remain(step, self.max_iter))\n",
        "                    print(log_str)\n",
        "\n",
        "                else:\n",
        "                    train_timer.tic()  # 计算每次迭代训练的起始时间\n",
        "                    summary_str, _ = self.sess.run(\n",
        "                        [self.summary_op, self.train_op],\n",
        "                        feed_dict=feed_dict)  # 开始迭代训练，每一次迭代后global_step自加1\n",
        "                    train_timer.toc()  # 计算这次迭代训练所使用的时间\n",
        "\n",
        "                self.writer.add_summary(summary_str, step)  # 将summary写入文件\n",
        "\n",
        "            else:\n",
        "                train_timer.tic()  # 计算每次迭代训练的起始时间\n",
        "                self.sess.run(self.train_op, feed_dict=feed_dict)  # 开始迭代训练，每一次迭代后global_step自加1\n",
        "                train_timer.toc()  # 计算这次迭代训练所使用的时间\n",
        "\n",
        "            # 每迭代save_iter次，保存一次模型\n",
        "            if step % self.save_iter == 0:\n",
        "                print('{} Saving checkpoint file to: {}'.format(\n",
        "                    datetime.datetime.now().strftime('%m-%d %H:%M:%S'),\n",
        "                    self.output_dir))\n",
        "                self.saver.save(\n",
        "                    self.sess, self.ckpt_file, global_step=self.global_step)\n",
        "\n",
        "    def save_cfg(self):\n",
        "        \"\"\"\n",
        "        保存配置信息\n",
        "        \"\"\"\n",
        "\n",
        "        with open(os.path.join(self.output_dir, 'config.txt'), 'w') as f:\n",
        "            cfg_dict = cfg.__dict__\n",
        "            for key in sorted(cfg_dict.keys()):\n",
        "                if key[0].isupper():\n",
        "                    cfg_str = '{}: {}\\n'.format(key, cfg_dict[key])\n",
        "                    f.write(cfg_str)\n",
        "\n",
        "\n",
        "def update_config_paths(data_dir, weights_file):\n",
        "    \"\"\"\n",
        "    数据集路径，和模型检查点文件路径\n",
        "\n",
        "    :param data_dir: 数据文件夹  数据集放在pascal_voc目录下\n",
        "    :param weights_file: 检查点文件名 该文件放在数据集目录下的weights文件夹下\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    cfg.DATA_PATH = data_dir\n",
        "    cfg.PASCAL_PATH = os.path.join(data_dir, 'pascal_voc')  # 数据所在文件夹\n",
        "    cfg.CACHE_PATH = os.path.join(cfg.PASCAL_PATH, 'cache')  # VOC2007数据所在文件夹\n",
        "    cfg.OUTPUT_DIR = os.path.join(cfg.PASCAL_PATH, 'output')  # 保存生成的数据集标签缓冲文件所在文件夹\n",
        "    cfg.WEIGHTS_DIR = os.path.join(cfg.PASCAL_PATH, 'weights')  # 保存生成的网络模型和日志文件所在的文件夹\n",
        "    cfg.WEIGHTS_FILE = os.path.join(cfg.WEIGHTS_DIR, weights_file)  # 检查点文件所在的目录\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 创建一个解析器对象，并告诉它将会有些什么参数。当程序运行时，该解析器就可以用于处理命令行参数。\n",
        "    parser = argparse.ArgumentParser()  # 定义参数\n",
        "    parser.add_argument('--weights', default=\"YOLO_small.ckpt\", type=str)  # 权重文件名\n",
        "    parser.add_argument('--data_dir', default=\"data\", type=str)  # 数据集路径\n",
        "    parser.add_argument('--threshold', default=0.2, type=float)\n",
        "    parser.add_argument('--iou_threshold', default=0.5, type=float)\n",
        "    parser.add_argument('--gpu', default='', type=str)\n",
        "    # 定义了所有参数之后，你就可以给 parse_args() 传递一组参数字符串来解析命令行。默认情况下，参数是从 sys.argv[1:] 中获取\n",
        "    # parse_args() 的返回值是一个命名空间，包含传递给命令的参数。该对象将参数保存其属性\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # 判断是否是使用gpu\n",
        "    if args.gpu is not None:\n",
        "        cfg.GPU = args.gpu\n",
        "\n",
        "    # 设定数据集路径，以及检查点文件路径\n",
        "    if args.data_dir != cfg.DATA_PATH:\n",
        "        update_config_paths(args.data_dir, args.weights)\n",
        "\n",
        "    # 设置环境变量\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = cfg.GPU\n",
        "\n",
        "    yolo = YOLONet()  # 创建YOLO网络对象\n",
        "    pascal = pascal_voc('train')  # 数据集对象\n",
        "\n",
        "    solver = Solver(yolo, pascal)  # 求解器对象\n",
        "\n",
        "    print('Start training ...')\n",
        "    solver.train()  # 开始训练\n",
        "    print('Done training.')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # python train.py --weights YOLO_small.ckpt --gpu 0\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VUp_T8F6S5DZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZSBLpPuQS4_N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}