{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L68dkgRRZvzO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from darknet import DarkNet\n",
        "from yolo_v1 import YOLOv1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLODetector:\n",
        "    def __init__(self,\n",
        "        model_path, class_name_list=None, mean_rgb=[122.67891434, 116.66876762, 104.00698793],\n",
        "        conf_thresh=0.1, prob_thresh=0.1, nms_thresh=0.5,\n",
        "        gpu_id=0):\n",
        "\n",
        "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
        "        use_gpu = torch.cuda.is_available()\n",
        "        assert use_gpu, 'Current implementation does not support CPU mode. Enable CUDA.'\n",
        "\n",
        "        # Load YOLO model.\n",
        "        print(\"Loading YOLO model...\")\n",
        "        darknet = DarkNet(conv_only=True, bn=True, init_weight=True)\n",
        "        darknet.features = torch.nn.DataParallel(darknet.features)\n",
        "        self.yolo = YOLOv1(darknet.features)\n",
        "        self.yolo.conv_layers = torch.nn.DataParallel(self.yolo.conv_layers)\n",
        "        self.yolo.load_state_dict(torch.load(model_path))\n",
        "        self.yolo.cuda()\n",
        "        print(\"Done loading!\")\n",
        "\n",
        "        self.yolo.eval()\n",
        "\n",
        "        self.S = self.yolo.feature_size\n",
        "        self.B = self.yolo.num_bboxes\n",
        "        self.C = self.yolo.num_classes\n",
        "\n",
        "        self.class_name_list = class_name_list if (class_name_list is not None) else list(VOC_CLASS_BGR.keys())\n",
        "        assert len(self.class_name_list) == self.C\n",
        "\n",
        "        self.mean = np.array(mean_rgb, dtype=np.float32)\n",
        "        assert self.mean.shape == (3,)\n",
        "\n",
        "        self.conf_thresh = conf_thresh\n",
        "        self.prob_thresh = prob_thresh\n",
        "        self.nms_thresh = nms_thresh\n",
        "\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "\n",
        "        # Warm up.\n",
        "        dummy_input = Variable(torch.zeros((1, 3, 448, 448)))\n",
        "        dummy_input = dummy_input.cuda()\n",
        "        for i in range(10):\n",
        "            self.yolo(dummy_input)\n",
        "\n",
        "    def detect(self, image_bgr, image_size=448):\n",
        "        \"\"\" Detect objects from given image.\n",
        "        Args:\n",
        "            image_bgr: (numpy array) input image in BGR ids_sorted, sized [h, w, 3].\n",
        "            image_size: (int) image width and height to which input image is resized.\n",
        "        Returns:\n",
        "            boxes_detected: (list of tuple) box corner list like [((x1, y1), (x2, y2))_obj1, ...]. Re-scaled for original input image size.\n",
        "            class_names_detected: (list of str) list of class name for each detected boxe.\n",
        "            probs_detected: (list of float) list of probability(=confidence x class_score) for each detected box.\n",
        "        \"\"\"\n",
        "        h, w, _ = image_bgr.shape\n",
        "        img = cv2.resize(image_bgr, dsize=(image_size, image_size), interpolation=cv2.INTER_LINEAR)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # assuming the model is trained with RGB images.\n",
        "        img = (img - self.mean) / 255.0\n",
        "        img = self.to_tensor(img) # [image_size, image_size, 3] -> [3, image_size, image_size]\n",
        "        img = img[None, :, :, :]  # [3, image_size, image_size] -> [1, 3, image_size, image_size]\n",
        "        img = Variable(img)\n",
        "        img = img.cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred_tensor = self.yolo(img)\n",
        "        pred_tensor = pred_tensor.cpu().data\n",
        "        pred_tensor = pred_tensor.squeeze(0) # squeeze batch dimension.\n",
        "\n",
        "        # Get detected boxes_detected, labels, confidences, class-scores.\n",
        "        boxes_normalized_all, class_labels_all, confidences_all, class_scores_all = self.decode(pred_tensor)\n",
        "        if boxes_normalized_all.size(0) == 0:\n",
        "            return [], [], [] # if no box found, return empty lists.\n",
        "\n",
        "        # Apply non maximum supression for boxes of each class.\n",
        "        boxes_normalized, class_labels, probs = [], [], []\n",
        "\n",
        "        for class_label in range(len(self.class_name_list)):\n",
        "            mask = (class_labels_all == class_label)\n",
        "            if torch.sum(mask) == 0:\n",
        "                continue # if no box found, skip that class.\n",
        "\n",
        "            boxes_normalized_masked = boxes_normalized_all[mask]\n",
        "            class_labels_maked = class_labels_all[mask]\n",
        "            confidences_masked = confidences_all[mask]\n",
        "            class_scores_masked = class_scores_all[mask]\n",
        "\n",
        "            ids = self.nms(boxes_normalized_masked, confidences_masked)\n",
        "\n",
        "            boxes_normalized.append(boxes_normalized_masked[ids])\n",
        "            class_labels.append(class_labels_maked[ids])\n",
        "            probs.append(confidences_masked[ids] * class_scores_masked[ids])\n",
        "\n",
        "        boxes_normalized = torch.cat(boxes_normalized, 0)\n",
        "        class_labels = torch.cat(class_labels, 0)\n",
        "        probs = torch.cat(probs, 0)\n",
        "\n",
        "        # Postprocess for box, labels, probs.\n",
        "        boxes_detected, class_names_detected, probs_detected = [], [], []\n",
        "        for b in range(boxes_normalized.size(0)):\n",
        "            box_normalized = boxes_normalized[b]\n",
        "            class_label = class_labels[b]\n",
        "            prob = probs[b]\n",
        "\n",
        "            x1, x2 = w * box_normalized[0], w * box_normalized[2] # unnormalize x with image width.\n",
        "            y1, y2 = h * box_normalized[1], h * box_normalized[3] # unnormalize y with image height.\n",
        "            boxes_detected.append(((x1, y1), (x2, y2)))\n",
        "\n",
        "            class_label = int(class_label) # convert from LongTensor to int.\n",
        "            class_name = self.class_name_list[class_label]\n",
        "            class_names_detected.append(class_name)\n",
        "\n",
        "            prob = float(prob) # convert from Tensor to float.\n",
        "            probs_detected.append(prob)\n",
        "\n",
        "        return boxes_detected, class_names_detected, probs_detected\n",
        "\n",
        "    def decode(self, pred_tensor):\n",
        "        \"\"\" Decode tensor into box coordinates, class labels, and probs_detected.\n",
        "        Args:\n",
        "            pred_tensor: (tensor) tensor to decode sized [S, S, 5 x B + C], 5=(x, y, w, h, conf)\n",
        "        Returns:\n",
        "            boxes: (tensor) [[x1, y1, x2, y2]_obj1, ...]. Normalized from 0.0 to 1.0 w.r.t. image width/height, sized [n_boxes, 4].\n",
        "            labels: (tensor) class labels for each detected boxe, sized [n_boxes,].\n",
        "            confidences: (tensor) objectness confidences for each detected box, sized [n_boxes,].\n",
        "            class_scores: (tensor) scores for most likely class for each detected box, sized [n_boxes,].\n",
        "        \"\"\"\n",
        "        S, B, C = self.S, self.B, self.C\n",
        "        boxes, labels, confidences, class_scores = [], [], [], []\n",
        "\n",
        "        cell_size = 1.0 / float(S)\n",
        "\n",
        "        conf = pred_tensor[:, :, 4].unsqueeze(2) # [S, S, 1]\n",
        "        for b in range(1, B):\n",
        "            conf = torch.cat((conf, pred_tensor[:, :, 5*b + 4].unsqueeze(2)), 2)\n",
        "        conf_mask = conf > self.conf_thresh # [S, S, B]\n",
        "\n",
        "        # TBM, further optimization may be possible by replacing the following for-loops with tensor operations.\n",
        "        for i in range(S): # for x-dimension.\n",
        "            for j in range(S): # for y-dimension.\n",
        "                class_score, class_label = torch.max(pred_tensor[j, i, 5*B:], 0)\n",
        "\n",
        "                for b in range(B):\n",
        "                    conf = pred_tensor[j, i, 5*b + 4]\n",
        "                    prob = conf * class_score\n",
        "                    if float(prob) < self.prob_thresh:\n",
        "                        continue\n",
        "\n",
        "                    # Compute box corner (x1, y1, x2, y2) from tensor.\n",
        "                    box = pred_tensor[j, i, 5*b : 5*b + 4]\n",
        "                    x0y0_normalized = torch.FloatTensor([i, j]) * cell_size # cell left-top corner. Normalized from 0.0 to 1.0 w.r.t. image width/height.\n",
        "                    xy_normalized = box[:2] * cell_size + x0y0_normalized   # box center. Normalized from 0.0 to 1.0 w.r.t. image width/height.\n",
        "                    wh_normalized = box[2:] # Box width and height. Normalized from 0.0 to 1.0 w.r.t. image width/height.\n",
        "                    box_xyxy = torch.FloatTensor(4) # [4,]\n",
        "                    box_xyxy[:2] = xy_normalized - 0.5 * wh_normalized # left-top corner (x1, y1).\n",
        "                    box_xyxy[2:] = xy_normalized + 0.5 * wh_normalized # right-bottom corner (x2, y2).\n",
        "\n",
        "                    # Append result to the lists.\n",
        "                    boxes.append(box_xyxy)\n",
        "                    labels.append(class_label)\n",
        "                    confidences.append(conf)\n",
        "                    class_scores.append(class_score)\n",
        "\n",
        "        if len(boxes) > 0:\n",
        "            boxes = torch.stack(boxes, 0) # [n_boxes, 4]\n",
        "            labels = torch.stack(labels, 0)             # [n_boxes, ]\n",
        "            confidences = torch.stack(confidences, 0)   # [n_boxes, ]\n",
        "            class_scores = torch.stack(class_scores, 0) # [n_boxes, ]\n",
        "        else:\n",
        "            # If no box found, return empty tensors.\n",
        "            boxes = torch.FloatTensor(0, 4)\n",
        "            labels = torch.LongTensor(0)\n",
        "            confidences = torch.FloatTensor(0)\n",
        "            class_scores = torch.FloatTensor(0)\n",
        "\n",
        "        return boxes, labels, confidences, class_scores"
      ],
      "metadata": {
        "id": "UCyx9PCoaQAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# VOC class names and BGR color.\n",
        "VOC_CLASS_BGR = {\n",
        "    'aeroplane': (128, 0, 0),\n",
        "    'bicycle': (0, 128, 0),\n",
        "    'bird': (128, 128, 0),\n",
        "    'boat': (0, 0, 128),\n",
        "    'bottle': (128, 0, 128),\n",
        "    'bus': (0, 128, 128),\n",
        "    'car': (128, 128, 128),\n",
        "    'cat': (64, 0, 0),\n",
        "    'chair': (192, 0, 0),\n",
        "    'cow': (64, 128, 0),\n",
        "    'diningtable': (192, 128, 0),\n",
        "    'dog': (64, 0, 128),\n",
        "    'horse': (192, 0, 128),\n",
        "    'motorbike': (64, 128, 128),\n",
        "    'person': (192, 128, 128),\n",
        "    'pottedplant': (0, 64, 0),\n",
        "    'sheep': (128, 64, 0),\n",
        "    'sofa': (0, 192, 0),\n",
        "    'train': (128, 192, 0),\n",
        "    'tvmonitor': (0, 64, 128)\n",
        "}\n",
        "\n",
        "\n",
        "def visualize_boxes(image_bgr, boxes, class_names, probs, name_bgr_dict=None, line_thickness=2):\n",
        "    if name_bgr_dict is None:\n",
        "        name_bgr_dict = VOC_CLASS_BGR\n",
        "\n",
        "    image_boxes = image_bgr.copy()\n",
        "    for box, class_name, prob in zip(boxes, class_names, probs):\n",
        "        # Draw box on the image.\n",
        "        left_top, right_bottom = box\n",
        "        left, top = int(left_top[0]), int(left_top[1])\n",
        "        right, bottom = int(right_bottom[0]), int(right_bottom[1])\n",
        "        bgr = name_bgr_dict[class_name]\n",
        "        cv2.rectangle(image_boxes, (left, top), (right, bottom), bgr, thickness=line_thickness)\n",
        "\n",
        "        # Draw text on the image.\n",
        "        text = '%s %.2f' % (class_name, prob)\n",
        "        size, baseline = cv2.getTextSize(text,  cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, thickness=2)\n",
        "        text_w, text_h = size\n",
        "\n",
        "        x, y = left, top\n",
        "        x1y1 = (x, y)\n",
        "        x2y2 = (x + text_w + line_thickness, y + text_h + line_thickness + baseline)\n",
        "        cv2.rectangle(image_boxes, x1y1, x2y2, bgr, -1)\n",
        "        cv2.putText(image_boxes, text, (x + line_thickness, y + 2*baseline + line_thickness),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.4, color=(255, 255, 255), thickness=1, lineType=8)\n",
        "\n",
        "    return image_boxes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def nms(self, boxes, scores):\n",
        "        \"\"\" Apply non maximum supression.\n",
        "        Args:\n",
        "        Returns:\n",
        "        \"\"\"\n",
        "        threshold = self.nms_thresh\n",
        "\n",
        "        x1 = boxes[:, 0] # [n,]\n",
        "        y1 = boxes[:, 1] # [n,]\n",
        "        x2 = boxes[:, 2] # [n,]\n",
        "        y2 = boxes[:, 3] # [n,]\n",
        "        areas = (x2 - x1) * (y2 - y1) # [n,]\n",
        "\n",
        "        _, ids_sorted = scores.sort(0, descending=True) # [n,]\n",
        "        ids = []\n",
        "        while ids_sorted.numel() > 0:\n",
        "            # Assume `ids_sorted` size is [m,] in the beginning of this iter.\n",
        "\n",
        "            i = ids_sorted.item() if (ids_sorted.numel() == 1) else ids_sorted[0]\n",
        "            ids.append(i)\n",
        "\n",
        "            if ids_sorted.numel() == 1:\n",
        "                break # If only one box is left (i.e., no box to supress), break.\n",
        "\n",
        "            inter_x1 = x1[ids_sorted[1:]].clamp(min=x1[i]) # [m-1, ]\n",
        "            inter_y1 = y1[ids_sorted[1:]].clamp(min=y1[i]) # [m-1, ]\n",
        "            inter_x2 = x2[ids_sorted[1:]].clamp(max=x2[i]) # [m-1, ]\n",
        "            inter_y2 = y2[ids_sorted[1:]].clamp(max=y2[i]) # [m-1, ]\n",
        "            inter_w = (inter_x2 - inter_x1).clamp(min=0) # [m-1, ]\n",
        "            inter_h = (inter_y2 - inter_y1).clamp(min=0) # [m-1, ]\n",
        "\n",
        "            inters = inter_w * inter_h # intersections b/w/ box `i` and other boxes, sized [m-1, ].\n",
        "            unions = areas[i] + areas[ids_sorted[1:]] - inters # unions b/w/ box `i` and other boxes, sized [m-1, ].\n",
        "            ious = inters / unions # [m-1, ]\n",
        "\n",
        "            # Remove boxes whose IoU is higher than the threshold.\n",
        "            ids_keep = (ious <= threshold).nonzero().squeeze() # [m-1, ]. Because `nonzero()` adds extra dimension, squeeze it.\n",
        "            if ids_keep.numel() == 0:\n",
        "                break # If no box left, break.\n",
        "            ids_sorted = ids_sorted[ids_keep+1] # `+1` is needed because `ids_sorted[0] = i`.\n",
        "\n",
        "        return torch.LongTensor(ids)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Paths to input/output images.\n",
        "    image_path = 'data/test_samples/009046.jpg'\n",
        "    out_path = 'result.png'\n",
        "    # Path to the yolo weight.\n",
        "    model_path = 'weights/yolo/model_best.pth'\n",
        "    # GPU device on which yolo is loaded.\n",
        "    gpu_id = 0\n",
        "\n",
        "    # Load model.\n",
        "    yolo = YOLODetector(model_path, gpu_id=gpu_id, conf_thresh=0.1, prob_thresh=0.1, nms_thresh=0.35)\n",
        "\n",
        "    # Load image.\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Detect objects.\n",
        "    boxes, class_names, probs = yolo.detect(image)\n",
        "\n",
        "    # Visualize.\n",
        "    image_boxes = visualize_boxes(image, boxes, class_names, probs)\n",
        "\n",
        "    # Output detection result as an image.\n",
        "    cv2.imwrite(out_path, image_boxes)"
      ],
      "metadata": {
        "id": "-UsKeKlWZ0d7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}