{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIt7onaiazka"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Loss(nn.Module):\n",
        "\n",
        "    def __init__(self, feature_size=7, num_bboxes=2, num_classes=20, lambda_coord=5.0, lambda_noobj=0.5):\n",
        "        \"\"\" Constructor.\n",
        "        Args:\n",
        "            feature_size: (int) size of input feature map.\n",
        "            num_bboxes: (int) number of bboxes per each cell.\n",
        "            num_classes: (int) number of the object classes.\n",
        "            lambda_coord: (float) weight for bbox location/size losses.\n",
        "            lambda_noobj: (float) weight for no-objectness loss.\n",
        "        \"\"\"\n",
        "        super(Loss, self).__init__()\n",
        "\n",
        "        self.S = feature_size\n",
        "        self.B = num_bboxes\n",
        "        self.C = num_classes\n",
        "        self.lambda_coord = lambda_coord\n",
        "        self.lambda_noobj = lambda_noobj\n",
        "\n",
        "\n",
        "    def compute_iou(self, bbox1, bbox2):\n",
        "        \"\"\" Compute the IoU (Intersection over Union) of two set of bboxes, each bbox format: [x1, y1, x2, y2].\n",
        "        Args:\n",
        "            bbox1: (Tensor) bounding bboxes, sized [N, 4].\n",
        "            bbox2: (Tensor) bounding bboxes, sized [M, 4].\n",
        "        Returns:\n",
        "            (Tensor) IoU, sized [N, M].\n",
        "        \"\"\"\n",
        "        N = bbox1.size(0)\n",
        "        M = bbox2.size(0)\n",
        "\n",
        "        # Compute left-top coordinate of the intersections\n",
        "        lt = torch.max(\n",
        "            bbox1[:, :2].unsqueeze(1).expand(N, M, 2), # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
        "            bbox2[:, :2].unsqueeze(0).expand(N, M, 2)  # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
        "        )\n",
        "        # Conpute right-bottom coordinate of the intersections\n",
        "        rb = torch.min(\n",
        "            bbox1[:, 2:].unsqueeze(1).expand(N, M, 2), # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
        "            bbox2[:, 2:].unsqueeze(0).expand(N, M, 2)  # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
        "        )\n",
        "        # Compute area of the intersections from the coordinates\n",
        "        wh = rb - lt   # width and height of the intersection, [N, M, 2]\n",
        "        wh[wh < 0] = 0 # clip at 0\n",
        "        inter = wh[:, :, 0] * wh[:, :, 1] # [N, M]\n",
        "\n",
        "        # Compute area of the bboxes\n",
        "        area1 = (bbox1[:, 2] - bbox1[:, 0]) * (bbox1[:, 3] - bbox1[:, 1]) # [N, ]\n",
        "        area2 = (bbox2[:, 2] - bbox2[:, 0]) * (bbox2[:, 3] - bbox2[:, 1]) # [M, ]\n",
        "        area1 = area1.unsqueeze(1).expand_as(inter) # [N, ] -> [N, 1] -> [N, M]\n",
        "        area2 = area2.unsqueeze(0).expand_as(inter) # [M, ] -> [1, M] -> [N, M]\n",
        "\n",
        "        # Compute IoU from the areas\n",
        "        union = area1 + area2 - inter # [N, M, 2]\n",
        "        iou = inter / union           # [N, M, 2]\n",
        "\n",
        "        return iou\n",
        "\n",
        "    def forward(self, pred_tensor, target_tensor):\n",
        "        \"\"\" Compute loss for YOLO training.\n",
        "        Args:\n",
        "            pred_tensor: (Tensor) predictions, sized [n_batch, S, S, Bx5+C], 5=len([x, y, w, h, conf]).\n",
        "            target_tensor: (Tensor) targets, sized [n_batch, S, S, Bx5+C].\n",
        "        Returns:\n",
        "            (Tensor): loss, sized [1, ].\n",
        "        \"\"\"\n",
        "        # TODO: Romove redundant dimensions for some Tensors.\n",
        "\n",
        "        S, B, C = self.S, self.B, self.C\n",
        "        N = 5 * B + C    # 5=len([x, y, w, h, conf]\n",
        "\n",
        "        batch_size = pred_tensor.size(0)\n",
        "        coord_mask = target_tensor[:, :, :, 4] > 0  # mask for the cells which contain objects. [n_batch, S, S]\n",
        "        noobj_mask = target_tensor[:, :, :, 4] == 0 # mask for the cells which do not contain objects. [n_batch, S, S]\n",
        "        coord_mask = coord_mask.unsqueeze(-1).expand_as(target_tensor) # [n_batch, S, S] -> [n_batch, S, S, N]\n",
        "        noobj_mask = noobj_mask.unsqueeze(-1).expand_as(target_tensor) # [n_batch, S, S] -> [n_batch, S, S, N]\n",
        "\n",
        "        coord_pred = pred_tensor[coord_mask].view(-1, N)            # pred tensor on the cells which contain objects. [n_coord, N]\n",
        "                                                                    # n_coord: number of the cells which contain objects.\n",
        "        bbox_pred = coord_pred[:, :5*B].contiguous().view(-1, 5)    # [n_coord x B, 5=len([x, y, w, h, conf])]\n",
        "        class_pred = coord_pred[:, 5*B:]                            # [n_coord, C]\n",
        "\n",
        "        coord_target = target_tensor[coord_mask].view(-1, N)        # target tensor on the cells which contain objects. [n_coord, N]\n",
        "                                                                    # n_coord: number of the cells which contain objects.\n",
        "        bbox_target = coord_target[:, :5*B].contiguous().view(-1, 5)# [n_coord x B, 5=len([x, y, w, h, conf])]\n",
        "        class_target = coord_target[:, 5*B:]                        # [n_coord, C]\n",
        "\n",
        "        # Compute loss for the cells with no object bbox.\n",
        "        noobj_pred = pred_tensor[noobj_mask].view(-1, N)        # pred tensor on the cells which do not contain objects. [n_noobj, N]\n",
        "                                                                # n_noobj: number of the cells which do not contain objects.\n",
        "        noobj_target = target_tensor[noobj_mask].view(-1, N)    # target tensor on the cells which do not contain objects. [n_noobj, N]\n",
        "                                                                # n_noobj: number of the cells which do not contain objects.\n",
        "        noobj_conf_mask = torch.cuda.ByteTensor(noobj_pred.size()).fill_(0) # [n_noobj, N]\n",
        "        for b in range(B):\n",
        "            noobj_conf_mask[:, 4 + b*5] = 1 # noobj_conf_mask[:, 4] = 1; noobj_conf_mask[:, 9] = 1\n",
        "        noobj_pred_conf = noobj_pred[noobj_conf_mask]       # [n_noobj, 2=len([conf1, conf2])]\n",
        "        noobj_target_conf = noobj_target[noobj_conf_mask]   # [n_noobj, 2=len([conf1, conf2])]\n",
        "        loss_noobj = F.mse_loss(noobj_pred_conf, noobj_target_conf, reduction='sum')\n",
        "\n",
        "        # Compute loss for the cells with objects.\n",
        "        coord_response_mask = torch.cuda.ByteTensor(bbox_target.size()).fill_(0)    # [n_coord x B, 5]\n",
        "        coord_not_response_mask = torch.cuda.ByteTensor(bbox_target.size()).fill_(1)# [n_coord x B, 5]\n",
        "        bbox_target_iou = torch.zeros(bbox_target.size()).cuda()                    # [n_coord x B, 5], only the last 1=(conf,) is used\n",
        "\n",
        "        # Choose the predicted bbox having the highest IoU for each target bbox.\n",
        "        for i in range(0, bbox_target.size(0), B):\n",
        "            pred = bbox_pred[i:i+B] # predicted bboxes at i-th cell, [B, 5=len([x, y, w, h, conf])]\n",
        "            pred_xyxy = Variable(torch.FloatTensor(pred.size())) # [B, 5=len([x1, y1, x2, y2, conf])]\n",
        "            # Because (center_x,center_y)=pred[:, 2] and (w,h)=pred[:,2:4] are normalized for cell-size and image-size respectively,\n",
        "            # rescale (center_x,center_y) for the image-size to compute IoU correctly.\n",
        "            pred_xyxy[:,  :2] = pred[:, :2]/float(S) - 0.5 * pred[:, 2:4]\n",
        "            pred_xyxy[:, 2:4] = pred[:, :2]/float(S) + 0.5 * pred[:, 2:4]\n",
        "\n",
        "            target = bbox_target[i] # target bbox at i-th cell. Because target boxes contained by each cell are identical in current implementation, enough to extract the first one.\n",
        "            target = bbox_target[i].view(-1, 5) # target bbox at i-th cell, [1, 5=len([x, y, w, h, conf])]\n",
        "            target_xyxy = Variable(torch.FloatTensor(target.size())) # [1, 5=len([x1, y1, x2, y2, conf])]\n",
        "            # Because (center_x,center_y)=target[:, 2] and (w,h)=target[:,2:4] are normalized for cell-size and image-size respectively,\n",
        "            # rescale (center_x,center_y) for the image-size to compute IoU correctly.\n",
        "            target_xyxy[:,  :2] = target[:, :2]/float(S) - 0.5 * target[:, 2:4]\n",
        "            target_xyxy[:, 2:4] = target[:, :2]/float(S) + 0.5 * target[:, 2:4]\n",
        "\n",
        "            iou = self.compute_iou(pred_xyxy[:, :4], target_xyxy[:, :4]) # [B, 1]\n",
        "            max_iou, max_index = iou.max(0)\n",
        "            max_index = max_index.data.cuda()\n",
        "\n",
        "            coord_response_mask[i+max_index] = 1\n",
        "            coord_not_response_mask[i+max_index] = 0\n",
        "\n",
        "            # \"we want the confidence score to equal the intersection over union (IOU) between the predicted box and the ground truth\"\n",
        "            # from the original paper of YOLO.\n",
        "            bbox_target_iou[i+max_index, torch.LongTensor([4]).cuda()] = (max_iou).data.cuda()\n",
        "        bbox_target_iou = Variable(bbox_target_iou).cuda()\n",
        "\n",
        "        # BBox location/size and objectness loss for the response bboxes.\n",
        "        bbox_pred_response = bbox_pred[coord_response_mask].view(-1, 5)      # [n_response, 5]\n",
        "        bbox_target_response = bbox_target[coord_response_mask].view(-1, 5)  # [n_response, 5], only the first 4=(x, y, w, h) are used\n",
        "        target_iou = bbox_target_iou[coord_response_mask].view(-1, 5)        # [n_response, 5], only the last 1=(conf,) is used\n",
        "        loss_xy = F.mse_loss(bbox_pred_response[:, :2], bbox_target_response[:, :2], reduction='sum')\n",
        "        loss_wh = F.mse_loss(torch.sqrt(bbox_pred_response[:, 2:4]), torch.sqrt(bbox_target_response[:, 2:4]), reduction='sum')\n",
        "        loss_obj = F.mse_loss(bbox_pred_response[:, 4], target_iou[:, 4], reduction='sum')\n",
        "\n",
        "        # Class probability loss for the cells which contain objects.\n",
        "        loss_class = F.mse_loss(class_pred, class_target, reduction='sum')\n",
        "\n",
        "        # Total loss\n",
        "        loss = self.lambda_coord * (loss_xy + loss_wh) + loss_obj + self.lambda_noobj * loss_noobj + loss_class\n",
        "        loss = loss / float(batch_size)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "PLeR27qTa44c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}