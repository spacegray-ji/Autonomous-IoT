{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3VDcheOy0QNY","executionInfo":{"status":"ok","timestamp":1663429624671,"user_tz":-540,"elapsed":24000,"user":{"displayName":"김희원","userId":"13562236615599718077"}},"outputId":"6e5f7e1c-0d7b-4947-ca14-405543878f4b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/Colab_Notebooks/YOLO/yolo_v1_pytorch-master/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ciQmdki0QvF","executionInfo":{"status":"ok","timestamp":1663391291847,"user_tz":-540,"elapsed":1484,"user":{"displayName":"김희원","userId":"13562236615599718077"}},"outputId":"dfbf0001-ddb2-45a0-e8d0-74bf67cf69ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab_Notebooks/YOLO/yolo_v1_pytorch-master\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XTAYVhnhahDM"},"outputs":[],"source":["\n","import os\n","from collections import defaultdict\n","from tqdm import tqdm\n","import numpy as np\n","import cv2\n","\n","from detect import YOLODetector, VOC_CLASS_BGR\n","\n","\n"]},{"cell_type":"code","source":["def compute_average_precision(recall, precision):\n","    \"\"\" Compute AP for one class.\n","    Args:\n","        recall: (numpy array) recall values of precision-recall curve.\n","        precision: (numpy array) precision values of precision-recall curve.\n","    Returns:\n","        (float) average precision (AP) for the class.\n","    \"\"\"\n","    # AP (AUC of precision-recall curve) computation using all points interpolation.\n","    # For mAP computation, you can find a great explaination below.\n","    # https://github.com/rafaelpadilla/Object-Detection-Metrics\n","\n","    recall = np.concatenate(([0.0], recall, [1.0]))\n","    precision = np.concatenate(([0.0], precision, [0.0]))\n","\n","    for i in range(precision.size - 1, 0, -1):\n","        precision[i - 1] = max(precision[i -1], precision[i])\n","\n","    ap = 0.0 # average precision (AUC of the precision-recall curve).\n","    for i in range(precision.size - 1):\n","        ap += (recall[i + 1] - recall[i]) * precision[i + 1]\n","\n","    return ap\n","\n","\n","def evaluate(preds,targets,class_names,threshold=0.5):\n","    \"\"\" Compute mAP metric.\n","    Args:\n","        preds: (dict) {class_name_1: [[filename, prob, x1, y1, x2, y2], ...], class_name_2: [[], ...], ...}.\n","        targets: (dict) {(filename, class_name): [[x1, y1, x2, y2], ...], ...}.\n","        class_names: (list) list of class names.\n","        threshold: (float) threshold for IoU to separate TP from FP.\n","    Returns:\n","        (list of float) list of average precision (AP) for each class.\n","    \"\"\"\n","    # For mAP computation, you can find a great explaination below.\n","    # https://github.com/rafaelpadilla/Object-Detection-Metrics\n","\n","    aps = [] # list of average precisions (APs) for each class.\n","\n","    for class_name in class_names:\n","        class_preds = preds[class_name] # all predicted objects for this class.\n","\n","        if len(class_preds) == 0:\n","            ap = 0.0 # if no box detected, assigne 0 for AP of this class.\n","            print('---class {} AP {}---'.format(class_name, ap))\n","            aps.append(ap)\n","            break\n","\n","        image_fnames = [pred[0]  for pred in class_preds]\n","        probs        = [pred[1]  for pred in class_preds]\n","        boxes        = [pred[2:] for pred in class_preds]\n","\n","        # Sort lists by probs.\n","        sorted_idxs = np.argsort(probs)[::-1]\n","        image_fnames = [image_fnames[i] for i in sorted_idxs]\n","        boxes        = [boxes[i]        for i in sorted_idxs]\n","\n","        # Compute total number of ground-truth boxes. This is used to compute precision later.\n","        num_gt_boxes = 0\n","        for (filename_gt, class_name_gt) in targets:\n","            if class_name_gt == class_name:\n","                num_gt_boxes += len(targets[filename_gt, class_name_gt])\n","\n","        # Go through sorted lists, classifying each detection into TP or FP.\n","        num_detections = len(boxes)\n","        tp = np.zeros(num_detections) # if detection `i` is TP, tp[i] = 1. Otherwise, tp[i] = 0.\n","        fp = np.ones(num_detections)  # if detection `i` is FP, fp[i] = 1. Otherwise, fp[i] = 0.\n","\n","        for det_idx, (filename, box) in enumerate(zip(image_fnames, boxes)):\n","\n","            if (filename, class_name) in targets:\n","                boxes_gt = targets[(filename, class_name)]\n","                for box_gt in boxes_gt:\n","                    # Compute IoU b/w/ predicted and groud-truth boxes.\n","                    inter_x1 = max(box_gt[0], box[0])\n","                    inter_y1 = max(box_gt[1], box[1])\n","                    inter_x2 = min(box_gt[2], box[2])\n","                    inter_y2 = min(box_gt[3], box[3])\n","                    inter_w = max(0.0, inter_x2 - inter_x1 + 1.0)\n","                    inter_h = max(0.0, inter_y2 - inter_y1 + 1.0)\n","                    inter = inter_w * inter_h\n","\n","                    area_det = (box[2] - box[0] + 1.0) * (box[3] - box[1] + 1.0)\n","                    area_gt = (box_gt[2] - box_gt[0] + 1.0) * (box_gt[3] - box_gt[1] + 1.0)\n","                    union = area_det + area_gt - inter\n","\n","                    iou = inter / union\n","                    if iou >= threshold:\n","                        tp[det_idx] = 1.0\n","                        fp[det_idx] = 0.0\n","\n","                        boxes_gt.remove(box_gt) # each ground-truth box can be assigned for only one detected box.\n","                        if len(boxes_gt) == 0:\n","                            del targets[(filename, class_name)] # remove empty element from the dictionary.\n","\n","                        break\n","\n","            else:\n","                pass # this detection is FP.\n","\n","        # Compute AP from `tp` and `fp`.\n","        tp_cumsum = np.cumsum(tp)\n","        fp_cumsum = np.cumsum(fp)\n","\n","        eps = np.finfo(np.float64).eps\n","        precision = tp_cumsum / np.maximum(tp_cumsum + fp_cumsum, eps)\n","        recall = tp_cumsum / float(num_gt_boxes)\n","\n","        ap = compute_average_precision(recall, precision)\n","        print('---class {} AP {}---'.format(class_name, ap))\n","        aps.append(ap)\n","\n","    # Compute mAP by averaging APs for all classes.\n","    print('---mAP {}---'.format(np.mean(aps)))\n","\n","    return aps\n","\n"],"metadata":{"id":"VFS5AzLVakc5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","if __name__ == '__main__':\n","    # Path to the yolo weight to test.\n","    model_path = 'weights/yolo/model_best.pth'\n","    # GPU device on which yolo is loaded.\n","    gpu_id = 0\n","    # Path to label file.\n","    label_path = 'data/voc2007test.txt'\n","    # Path to image dir.\n","    image_dir = 'data/VOC_allimgs/'\n","\n","\n","    voc_class_names = list(VOC_CLASS_BGR.keys())\n","    targets = defaultdict(list)\n","    preds = defaultdict(list)\n","\n","\n","    print('Preparing ground-truth data...')\n","\n","    # Load annotations from label file.\n","    annotations = []\n","    with open(label_path, 'r') as f:\n","        lines = f.readlines()\n","    for line in lines:\n","        anno = line.strip().split()\n","        annotations.append(anno)\n","\n","    # Prepare ground-truth data.\n","    image_fnames = []\n","    for anno in annotations:\n","        filename = anno[0]\n","        image_fnames.append(filename)\n","\n","        num_boxes = (len(anno) - 1) // 5\n","        for b in range(num_boxes):\n","            x1 = int(anno[5*b + 1])\n","            y1 = int(anno[5*b + 2])\n","            x2 = int(anno[5*b + 3])\n","            y2 = int(anno[5*b + 4])\n","\n","            class_label = int(anno[5*b + 5])\n","            class_name = voc_class_names[class_label]\n","\n","            targets[(filename, class_name)].append([x1, y1, x2, y2])\n","\n","\n","    print('Predicting...')\n","\n","    # Load YOLO model.\n","    yolo = YOLODetector(model_path, gpu_id=gpu_id, conf_thresh=-1.0, prob_thresh=-1.0, nms_thresh=0.45)\n","\n","    # Detect objects with the model.\n","    for filename in tqdm(image_fnames):\n","        image_path = os.path.join(image_dir, filename)\n","        image = cv2.imread(image_path)\n","\n","        boxes, class_names, probs = yolo.detect(image)\n","        for box, class_name, prob in zip(boxes, class_names, probs):\n","            x1y1, x2y2 = box\n","            x1, y1 = int(x1y1[0]), int(x1y1[1])\n","            x2, y2 = int(x2y2[0]), int(x2y2[1])\n","            preds[class_name].append([filename, prob, x1, y1, x2, y2])\n","\n","\n","    print('Evaluate the detection result...')\n","\n","    evaluate(preds, targets, class_names=voc_class_names)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":433},"id":"4PQCFt5E16jG","executionInfo":{"status":"error","timestamp":1663391317329,"user_tz":-540,"elapsed":7139,"user":{"displayName":"김희원","userId":"13562236615599718077"}},"outputId":"0607cdeb-43ce-4e93-99b8-ed00876dee91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Preparing ground-truth data...\n","Predicting...\n","Loading YOLO model...\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-e22a000e04a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Load YOLO model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0myolo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLODetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpu_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnms_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# Detect objects with the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Colab_Notebooks/YOLO/yolo_v1_pytorch-master/detect.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, class_name_list, mean_rgb, conf_thresh, prob_thresh, nms_thresh, gpu_id)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLOv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdarknet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done loading!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'weights/yolo/model_best.pth'"]}]}]}